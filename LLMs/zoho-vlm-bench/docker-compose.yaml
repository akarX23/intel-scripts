networks:
  vllm_net:
    driver: bridge

services:
  haproxy:
    image: haproxy:latest
    container_name: vllm-haproxy
    networks:
      - vllm_net
    ports:
      - "8000:8000" # Expose HAProxy to route traffic
    volumes:
      - "./ha-proxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro"
    depends_on:
      vllm-1:
        condition: service_healthy
      vllm-2:
        condition: service_healthy
      vllm-3:
        condition: service_healthy
      vllm-4:
        condition: service_healthy
      vllm-5:
        condition: service_healthy
      vllm-6:
        condition: service_healthy
    restart: always

  vllm-1:
    image: akarx/vllm-cpu-env-0.10.1
    container_name: vllm-server-1
    volumes:
      - "/home/sdp/.cache/huggingface:/root/.cache/huggingface"
    environment:
      - VLLM_CPU_OMP_THREADS_BIND=0-31
      - VLLM_CPU_KVCACHE_SPACE=64
      - VLLM_ENGINE_ITERATION_TIMEOUT_S=600
      - VLLM_ALLOW_LONG_MAX_MODEL_LEN=1
      - TORCHINDUCTOR_COMPILE_THREADS=1
      - VLLM_CPU_NUM_OF_RESERVED_CPU=2
      - VLLM_USE_V1=1
      - HUGGING_FACE_HUB_TOKEN=
      # - http_proxy=http://proxy-dmz.intel.com:912
      # - https_proxy=http://proxy-dmz.intel.com:912
      # - no_proxy=localhost
    # cpuset: "0-127"
    ports:
      - "8000:8000"
    command:
      - --model
      - llava-hf/llava-1.5-7b-hf
      - --dtype
      - bfloat16
      - --distributed-executor-backend
      - mp
      - --host
      - 0.0.0.0
      - --port
      - "8000"
      - -tp
      - "1"
      - --max-num-seqs
      - "4096"
      - --max-num-batched-tokens
      - "4096"
    privileged: true
    networks:
      - vllm_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/models"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  vllm-2:
    image: akarx/vllm-cpu-env-0.10.1
    container_name: vllm-server-2
    volumes:
      - "/home/sdp/.cache/huggingface:/root/.cache/huggingface"
    environment:
      - VLLM_CPU_OMP_THREADS_BIND=0-31
      - VLLM_CPU_KVCACHE_SPACE=64
      - VLLM_ENGINE_ITERATION_TIMEOUT_S=600
      - VLLM_ALLOW_LONG_MAX_MODEL_LEN=1
      - TORCHINDUCTOR_COMPILE_THREADS=1
      - VLLM_CPU_NUM_OF_RESERVED_CPU=2
      - VLLM_USE_V1=1
      - HUGGING_FACE_HUB_TOKEN=
      # - http_proxy=http://proxy-dmz.intel.com:912
      # - https_proxy=http://proxy-dmz.intel.com:912
      # - no_proxy=localhost
    # cpuset: "0-127"
    ports:
      - "8000:8000"
    command:
      - --model
      - llava-hf/llava-1.5-7b-hf
      - --dtype
      - bfloat16
      - --distributed-executor-backend
      - mp
      - --host
      - 0.0.0.0
      - --port
      - "8000"
      - -tp
      - "1"
      - --max-num-seqs
      - "4096"
      - --max-num-batched-tokens
      - "4096"
    privileged: true
    networks:
      - vllm_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/models"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  vllm-3:
    image: akarx/vllm-cpu-env-0.10.1
    container_name: vllm-server-3
    volumes:
      - "/home/sdp/.cache/huggingface:/root/.cache/huggingface"
    environment:
      - VLLM_CPU_OMP_THREADS_BIND=0-31
      - VLLM_CPU_KVCACHE_SPACE=64
      - VLLM_ENGINE_ITERATION_TIMEOUT_S=600
      - VLLM_ALLOW_LONG_MAX_MODEL_LEN=1
      - TORCHINDUCTOR_COMPILE_THREADS=1
      - VLLM_CPU_NUM_OF_RESERVED_CPU=2
      - VLLM_USE_V1=1
      - HUGGING_FACE_HUB_TOKEN=
      # - http_proxy=http://proxy-dmz.intel.com:912
      # - https_proxy=http://proxy-dmz.intel.com:912
      # - no_proxy=localhost
    # cpuset: "0-127"
    ports:
      - "8000:8000"
    command:
      - --model
      - llava-hf/llava-1.5-7b-hf
      - --dtype
      - bfloat16
      - --distributed-executor-backend
      - mp
      - --host
      - 0.0.0.0
      - --port
      - "8000"
      - -tp
      - "1"
      - --max-num-seqs
      - "4096"
      - --max-num-batched-tokens
      - "4096"
    privileged: true
    networks:
      - vllm_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/models"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  vllm-4:
    image: akarx/vllm-cpu-env-0.10.1
    container_name: vllm-server-4
    volumes:
      - "/home/sdp/.cache/huggingface:/root/.cache/huggingface"
    environment:
      - VLLM_CPU_OMP_THREADS_BIND=0-31
      - VLLM_CPU_KVCACHE_SPACE=64
      - VLLM_ENGINE_ITERATION_TIMEOUT_S=600
      - VLLM_ALLOW_LONG_MAX_MODEL_LEN=1
      - TORCHINDUCTOR_COMPILE_THREADS=1
      - VLLM_CPU_NUM_OF_RESERVED_CPU=2
      - VLLM_USE_V1=1
      - HUGGING_FACE_HUB_TOKEN=
      # - http_proxy=http://proxy-dmz.intel.com:912
      # - https_proxy=http://proxy-dmz.intel.com:912
      # - no_proxy=localhost
    # cpuset: "0-127"
    ports:
      - "8000:8000"
    command:
      - --model
      - llava-hf/llava-1.5-7b-hf
      - --dtype
      - bfloat16
      - --distributed-executor-backend
      - mp
      - --host
      - 0.0.0.0
      - --port
      - "8000"
      - -tp
      - "1"
      - --max-num-seqs
      - "4096"
      - --max-num-batched-tokens
      - "4096"
    privileged: true
    networks:
      - vllm_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/models"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # vllm-5:
  #   image: vllm-cpu-env
  #   restart: on-failure
  #   container_name: vllm-server-5
  #   volumes:
  #     - "/home/cefls_user/.cache/huggingface:/root/.cache/huggingface"
  #   environment:
  #     - VLLM_USE_V1=0
  #     - VLLM_ALLOW_LONG_MAX_MODEL_LEN=1
  #     - VLLM_ENGINE_ITERATION_TIMEOUT_S=600
  #     - VLLM_CPU_KVCACHE_SPACE=40
  #     - VLLM_CPU_OMP_THREADS_BIND=128-159
  #     - HUGGING_FACE_HUB_TOKEN=
  #     - http_proxy=http://proxy-dmz.intel.com:912
  #     - https_proxy=http://proxy-dmz.intel.com:912
  #     - no_proxy=localhost
  #   cpuset: "128-159"
  #   command:
  #     - --model
  #     - llava-hf/llava-v1.6-vicuna-13b-hf
  #     - -tp
  #     - "1"
  #     - --dtype
  #     - bfloat16
  #     - --max-num-batched-tokens
  #     - "16384"
  #     - --enable_chunked_prefill
  #     - "True"
  #   privileged: true
  #   networks:
  #     - vllm_net
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8000/v1/models"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 15
  #     start_period: 120s

  # vllm-6:
  #   image: vllm-cpu-env
  #   restart: on-failure
  #   container_name: vllm-server-6
  #   volumes:
  #     - "/home/cefls_user/.cache/huggingface:/root/.cache/huggingface"
  #   environment:
  #     - VLLM_USE_V1=0
  #     - VLLM_ALLOW_LONG_MAX_MODEL_LEN=1
  #     - VLLM_ENGINE_ITERATION_TIMEOUT_S=600
  #     - VLLM_CPU_KVCACHE_SPACE=40
  #     - VLLM_CPU_OMP_THREADS_BIND=160-191
  #     - HUGGING_FACE_HUB_TOKEN=
  #     - http_proxy=http://proxy-dmz.intel.com:912
  #     - https_proxy=http://proxy-dmz.intel.com:912
  #     - no_proxy=localhost
  #   cpuset: "160-191"
  #   command:
  #     - --model
  #     - llava-hf/llava-v1.6-vicuna-13b-hf
  #     - -tp
  #     - "1"
  #     - --dtype
  #     - bfloat16
  #     - --max-num-batched-tokens
  #     - "16384"
  #     - --enable_chunked_prefill
  #     - "True"
  #   privileged: true
  #   networks:
  #     - vllm_net
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8000/v1/models"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 15
  #     start_period: 120s